{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf5PD4ITHiXq"
      },
      "source": [
        " !apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "\n",
        "#!add-apt-repository -y ppa:alessandro-strada/ppa  # 2>&1 > /dev/null\n",
        "\n",
        "#!echo \"PPA ADDED\"\n",
        "#!apt-get update  # 2>&1 > /dev/null\n",
        "#!echo \"REPO UPDATED\"\n",
        "\n",
        "!apt install software-properties-common dirmngr gnupg-agent\n",
        "!apt-key adv --keyserver keyserver.ubuntu.com --recv-keys AD5F235DF639B041\n",
        "!echo 'deb http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu xenial main' | tee /etc/apt/sources.list.d/alessandro-strada-ubuntu-ppa.list >/dev/null\n",
        "!apt-get update\n",
        "!apt-get install -y -qq google-drive-ocamlfuse fuse\n",
        "!echo \"install done\"\n",
        "\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "\n",
        "!google-drive-ocamlfuse -headless -id {creds.client_id} -secret {creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "\n",
        "vcode = getpass.getpass()\n",
        "\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id {creds.client_id} -secret {creds.client_secret}\n",
        "#vcode = getpass.getpass()\n",
        "\n",
        "\n",
        "!mkdir -p drive\n",
        "\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "\n",
        "\n",
        "print('Files in Drive:')\n",
        "\n",
        "!ls drive/\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG6_BiJFJoyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a3aeb4-d8ba-484b-d2a7-c8e1fb473e85"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cigGaTAnklVy"
      },
      "source": [
        "import os\n",
        "import scipy\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "X_train=[]\n",
        "y_train=[]\n",
        "flg = False\n",
        "#!ls \"/content/drive/Train\"\n",
        "if (flg == False):\n",
        "  path=\"/content/drive/My Drive/Train/\"\n",
        "  s=os.listdir(\"/content/drive/My Drive/Train\")\n",
        "  print(len(s))\n",
        "  for i in range(len(s)):\n",
        "      direction=s[i]\n",
        "      tr=os.path.join(path,direction)\n",
        "      gh=cv2.imread(tr)\n",
        "      X_train.append(gh)\n",
        "      k=str.split(direction,'_')\n",
        "      if (k[0] == '100'):\n",
        "          y_train.append(4)\n",
        "      elif (k[0] == '5'):\n",
        "          y_train.append(0)\n",
        "      elif (k[0]=='10'):\n",
        "          y_train.append(1)\n",
        "      elif(k[0]=='25'):\n",
        "          y_train.append(2)\n",
        "      elif(k[0]=='50'):\n",
        "          y_train.append(3)\n",
        "      print(i)\n",
        "  y_train = np.array(y_train)\n",
        "  np.save(y_train , '/content/drive/MyDrive/temp.npy')\n",
        "else:\n",
        "  y_train = np.load('/content/drive/MyDrive/y_train.npy')\n",
        "\n",
        "\n",
        "X_test=[]\n",
        "X_test_name=[]\n",
        "path=\"/content/drive/My Drive/Test/\"\n",
        "s=os.listdir(\"/content/drive/My Drive/Test\")\n",
        "for i in range(len(s)):\n",
        "  direction=s[i]\n",
        "  tir=os.path.join(path,direction)\n",
        "  X_test.append(cv2.imread(tir))\n",
        "  X_test_name.append(direction)\n",
        "  print(i)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9gAoozkkll-"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "np.random.seed(2019)\n",
        "\n",
        "X_train=np.array(X_train)\n",
        "print(X_train.shape)\n",
        "X_test=np.array(X_test)\n",
        "trainX = np.reshape(X_train, [2352, 80, 80,3])\n",
        "testX = np.reshape(X_test, [600, 80, 80,3])\n",
        "\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "\n",
        "trainX_normal = (trainX/255.)\n",
        "testX_normal = (testX/255.)\n",
        "\n",
        "\n",
        "trainX_normal = trainX_normal.astype('float32')\n",
        "testX_normal = testX_normal.astype('float32')\n",
        "\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, 5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "790bV16okmBt"
      },
      "source": [
        "\n",
        "input_shape = (80, 80,3)\n",
        "model = Sequential()\n",
        "model.add(Dropout(0.2, input_shape=input_shape))\n",
        "model.add(Conv2D(8, kernel_size=(3, 3),\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "model.add(Conv2D(16, kernel_size=(3, 3),\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl5S-Zv_k5an",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "f024cf3d-d5c7-48e2-88de-f87bd593d18f"
      },
      "source": [
        "#decay_rate = 0.01\n",
        "#sgd = keras.optimizers.sgd(lr=0.1, momentum=0.9, decay=decay_rate)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(trainX_normal, Y_train,\n",
        "          batch_size=46,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          shuffle=True,\n",
        "          validation_split=0.1)  #validation_data=#(trainX_normal, Y_train))\n",
        "\n",
        "#score = model.evaluate(testX_normal, Y_test, verbose=1)\n",
        "#print('Test loss:', score[0])\n",
        "#print('Test accuracy:', score[1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0709 17:58:39.348661 140087265470336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0709 17:58:39.382738 140087265470336 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0709 17:58:39.655951 140087265470336 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 2000 samples, validate on 223 samples\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 6s 3ms/step - loss: 1.0794 - acc: 0.5755 - val_loss: 0.2320 - val_acc: 0.9372\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 1s 311us/step - loss: 0.6149 - acc: 0.8110 - val_loss: 0.2252 - val_acc: 0.9462\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 1s 309us/step - loss: 0.4885 - acc: 0.8560 - val_loss: 0.0844 - val_acc: 0.9910\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 1s 309us/step - loss: 0.4498 - acc: 0.8680 - val_loss: 0.0865 - val_acc: 0.9821\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 1s 295us/step - loss: 0.3686 - acc: 0.8950 - val_loss: 0.0736 - val_acc: 0.9731\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 1s 303us/step - loss: 0.3058 - acc: 0.9160 - val_loss: 0.1277 - val_acc: 0.9596\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 1s 296us/step - loss: 0.2863 - acc: 0.9170 - val_loss: 0.0520 - val_acc: 0.9821\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 1s 303us/step - loss: 0.2609 - acc: 0.9315 - val_loss: 0.0981 - val_acc: 0.9641\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 1s 297us/step - loss: 0.2259 - acc: 0.9410 - val_loss: 0.1132 - val_acc: 0.9596\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 1s 299us/step - loss: 0.2030 - acc: 0.9395 - val_loss: 0.0853 - val_acc: 0.9686\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6848f1b0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM-T9pbdNjCe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "71ebf6a2-a7a1-45ac-f4ce-c4165eb7074d"
      },
      "source": [
        "score = model.evaluate(trainX_normal, Y_train, verbose=1)\n",
        "print('Train loss:', score[0])\n",
        "print('Train accuracy:', score[1])\n",
        "predicted_classes=model.predict(testX_normal)\n",
        "print(predicted_classes[0])\n",
        "print(predicted_classes.shape)\n",
        "predicted_classes = np.argmax(np.round(predicted_classes),axis=1)\n",
        "#score = model.evaluate(testX_normal, Y_test, verbose=1)\n",
        "#print('Test loss:', score[0])\n",
        "#print('Test accuracy:', score[1])\n",
        "#print(predicted_classes)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2223/2223 [==============================] - 0s 170us/step\n",
            "Train loss: 0.3955470160440824\n",
            "Train accuracy: 0.8353576248849345\n",
            "[1.9577181e-03 9.9073762e-01 7.1797096e-03 1.2392621e-04 1.1201350e-06]\n",
            "(600, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjCRhV9CVxeg"
      },
      "source": [
        "import csv\n",
        "\n",
        "with open('/content/drive/My Drive/sample1.csv','w',newline='') as f:\n",
        "  H=csv.writer(f)\n",
        "  H.writerow(['ID','Predicted'])\n",
        "  for i in range(600):\n",
        "    k=str.split(X_test_name[i],'.')\n",
        "    if(predicted_classes[i]==0):\n",
        "      Target=[int(k[0])+1,5]\n",
        "      H.writerow(Target)\n",
        "    elif(predicted_classes[i]==1):\n",
        "      Target=[int(k[0])+1,10]\n",
        "      H.writerow(Target)\n",
        "    elif(predicted_classes[i]==2):\n",
        "      Target=[int(k[0])+1,25]\n",
        "      H.writerow(Target)\n",
        "    elif(predicted_classes[i]==3):\n",
        "      Target=[int(k[0])+1,50]\n",
        "      H.writerow(Target)\n",
        "    elif(predicted_classes[i]==4):\n",
        "      Target=[int(k[0])+1,100]\n",
        "      H.writerow(Target)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}